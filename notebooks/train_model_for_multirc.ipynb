{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPTNeoForSequenceClassification, AutoTokenizer, OPTForCausalLM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.judge import train_judge_for_babi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "set_seed(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import FALSE_LABEL_STR, TRUE_LABEL_STR\n",
    "\n",
    "id2label = {0: FALSE_LABEL_STR, 1: TRUE_LABEL_STR}\n",
    "label2id = {FALSE_LABEL_STR: 0, TRUE_LABEL_STR: 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/felix/.cache/huggingface/modules/datasets_modules/datasets/eraser_multi_rc/88c60ad5598eeedb78e952696a3735bf7e6efe34ac06577c4f20c0eccef78a33 (last modified on Tue Aug 15 10:26:08 2023) since it couldn't be found locally at eraser_multi_rc., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset eraser_multi_rc (/home/felix/.cache/huggingface/datasets/eraser_multi_rc/default/0.1.1/88c60ad5598eeedb78e952696a3735bf7e6efe34ac06577c4f20c0eccef78a33)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734fafaa99b24e2985b670d5d0f19128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multirc = datasets.load_dataset('eraser_multi_rc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "multirc_train = pd.DataFrame(multirc[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24029"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multirc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "multirc_val = pd.DataFrame(multirc[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_superfluous_spaces(sentence):\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'\\s+([,.\\'\\\"\\?])'\n",
    "    \n",
    "    # Replace the pattern with the matched character without extra spaces\n",
    "    cleaned_sentence = re.sub(pattern, r'\\1', sentence)\n",
    "    \n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(context, question, answer):\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_easy_prompt_from_row(row):\n",
    "    evidences = [remove_superfluous_spaces(e) for e in row['evidences']]\n",
    "    context = ' '.join(evidences)\n",
    "    question, answer = [\n",
    "        remove_superfluous_spaces(s) for s in row[\"query_and_answer\"].split(\" || \")\n",
    "    ]\n",
    "    return generate_prompt(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_easy_multi_rc_data(data):\n",
    "    easy_mrc_data = data.copy()\n",
    "    easy_mrc_data['prompt'] = easy_mrc_data.apply(\n",
    "        get_easy_prompt_from_row, axis=1\n",
    "    )\n",
    "    easy_mrc_data = easy_mrc_data[[\"prompt\", \"label\"]]\n",
    "    return easy_mrc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_prompt_from_row(row):\n",
    "    context = remove_superfluous_spaces(row[\"passage\"])\n",
    "    question, answer = [\n",
    "        remove_superfluous_spaces(s) for s in row[\"query_and_answer\"].split(\" || \")\n",
    "    ]\n",
    "    return generate_prompt(context, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hard_multi_rc_data(data):\n",
    "    hard_mrc_data = data.copy()\n",
    "    hard_mrc_data['prompt'] = hard_mrc_data.apply(\n",
    "        get_hard_prompt_from_row, axis=1\n",
    "    )\n",
    "    return hard_mrc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_mrc_train = generate_easy_multi_rc_data(multirc_train)\n",
    "easy_mrc_val = generate_easy_multi_rc_data(multirc_val)\n",
    "hard_mrc_train = generate_hard_multi_rc_data(multirc_train)\n",
    "hard_mrc_val = generate_hard_multi_rc_data(multirc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_mrc_train.to_csv(\"../data/processed/easy_mrc_train.csv\", index=False)\n",
    "easy_mrc_val.to_csv(\"../data/processed/easy_mrc_val.csv\", index=False)\n",
    "hard_mrc_train.to_csv(\"../data/processed/hard_mrc_train.csv\", index=False)\n",
    "hard_mrc_val.to_csv(\"../data/processed/hard_mrc_val.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int8_training = True  # https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/\n",
    "lora_training = True  # https://github.com/microsoft/LoRA\n",
    "autocast_training = True  # Trains with quantized weights. Only use if your hardware doesn't support int8_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, \n",
    "            label2id=label2id, load_in_8bit=int8_training, low_cpu_mem_usage=int8_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"gpt-neo-1.3B\"\n",
    "project_name = \"multiRC-Judge\"\n",
    "store_locally = False  # Set False if you want to delete any config + checkpoint files in models/ (doesn't delete from subdirectories)\n",
    "\n",
    "batch_size = 16\n",
    "lr = 5e-5\n",
    "lr_scheduler = None  # \"cosine-annealing\" | None\n",
    "\n",
    "epochs = 10\n",
    "acc_every_batch = 250\n",
    "eval_every_batch = 250\n",
    "save_every_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_judge_for_multirc(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_name=model_name,\n",
    "    run_name=run_name,\n",
    "    project_name=project_name,\n",
    "    device=device,\n",
    "    lr=lr,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    autocast_training=autocast_training,\n",
    "    int8_training=int8_training,\n",
    "    lora_training=lora_training,\n",
    "    batch_size=batch_size,\n",
    "    store_locally=store_locally,\n",
    "    epochs=epochs,\n",
    "    acc_every_batch=acc_every_batch,\n",
    "    eval_every_batch=eval_every_batch,\n",
    "    save_every_epoch=save_every_epoch,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5-rhys-OkinN51f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
