{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 09:40:27,541] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPTNeoForSequenceClassification, AutoTokenizer, OPTForCausalLM\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.judge import train_judge_for_babi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_seed\n",
    "set_seed(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import FALSE_LABEL_STR, TRUE_LABEL_STR\n",
    "\n",
    "id2label = {0: FALSE_LABEL_STR, 1: TRUE_LABEL_STR}\n",
    "label2id = {FALSE_LABEL_STR: 0, TRUE_LABEL_STR: 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "babi = datasets.load_dataset('Muennighoff/babi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "babi_train = pd.DataFrame(babi[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "babi_val = pd.DataFrame(babi[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary moved to the bathroom.\\nJohn went to the ...</td>\n",
       "      <td>Where is Mary?</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mary moved to the bathroom.\\nJohn went to the ...</td>\n",
       "      <td>Where is Daniel?</td>\n",
       "      <td>hallway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary moved to the bathroom.\\nJohn went to the ...</td>\n",
       "      <td>Where is Daniel?</td>\n",
       "      <td>hallway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mary moved to the bathroom.\\nJohn went to the ...</td>\n",
       "      <td>Where is Daniel?</td>\n",
       "      <td>office</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mary moved to the bathroom.\\nJohn went to the ...</td>\n",
       "      <td>Where is Sandra?</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             passage          question  \\\n",
       "0  Mary moved to the bathroom.\\nJohn went to the ...    Where is Mary?   \n",
       "1  Mary moved to the bathroom.\\nJohn went to the ...  Where is Daniel?   \n",
       "2  Mary moved to the bathroom.\\nJohn went to the ...  Where is Daniel?   \n",
       "3  Mary moved to the bathroom.\\nJohn went to the ...  Where is Daniel?   \n",
       "4  Mary moved to the bathroom.\\nJohn went to the ...  Where is Sandra?   \n",
       "\n",
       "     answer  task  \n",
       "0  bathroom     1  \n",
       "1   hallway     1  \n",
       "2   hallway     1  \n",
       "3    office     1  \n",
       "4  bathroom     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_string(task_n, idx=0, with_answer=False):\n",
    "    passage = babi_train[babi_train[\"task\"] == task_n].iloc[idx][\"passage\"]\n",
    "    question = babi_train[babi_train[\"task\"] == task_n].iloc[idx][\"question\"]\n",
    "    prompt = f\"Passage:\\n{passage}\\nQuestion:\\n{question}\\n\\nAnswer:\\n\"\n",
    "    if with_answer:\n",
    "        answer = babi_train[babi_train[\"task\"] == task_n].iloc[idx][\"answer\"]\n",
    "        prompt = f\"{prompt}{answer}\"\n",
    "    return prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_1_variations(question, correct_answer, possible_names=[]):\n",
    "    t1_possible_answers = ['hallway', 'garden', 'office', 'kitchen', 'bedroom', 'bathroom']\n",
    "\n",
    "    correct_answers = [correct_answer]\n",
    "    name = question.split(\" \")[2].split(\"?\")[0]\n",
    "    correct_answers.append(f\"{name} is in the {correct_answer}\")\n",
    "    correct_answers.append(f\"In the {correct_answer}\")\n",
    "\n",
    "    incorrect_answers = []\n",
    "    possible_incorrect_answers = list(t1_possible_answers)\n",
    "    possible_incorrect_answers.remove(correct_answer)\n",
    "    incorrect_answer = np.random.choice(possible_incorrect_answers, size=1)[0]\n",
    "\n",
    "    incorrect_answers.append(incorrect_answer)\n",
    "    incorrect_answers.append(f\"{name} is in the {incorrect_answer}\")\n",
    "\n",
    "\n",
    "    r = np.random.random()\n",
    "\n",
    "    if r < 0.75:\n",
    "        incorrect_answers.append(f\"In the {incorrect_answer}\")\n",
    "    elif r < 0.95:\n",
    "        possible_false_names = list(possible_names)\n",
    "        possible_false_names.remove(name)\n",
    "        false_name = np.random.choice(possible_false_names, size=1)[0]\n",
    "        incorrect_answers.append(f\"{false_name} is in the {correct_answer}\")\n",
    "    else:\n",
    "        incorrect_answers.append(\"\")\n",
    "\n",
    "    return correct_answers, incorrect_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_2_variations(question, correct_answer, possible_answers=[], possible_obj=[]):\n",
    "    correct_answers = [correct_answer]\n",
    "    obj = question.split(\" \")[3].split(\"?\")[0]\n",
    "    correct_answers.append(f\"{obj} is in the {correct_answer}\")\n",
    "    correct_answers.append(f\"In the {correct_answer}\")\n",
    "\n",
    "    incorrect_answers = []\n",
    "    possible_incorrect_answers = list(possible_answers)\n",
    "    possible_incorrect_answers.remove(correct_answer)\n",
    "    incorrect_answer = np.random.choice(possible_incorrect_answers, size=1)[0]\n",
    "\n",
    "    incorrect_answers.append(incorrect_answer)\n",
    "    incorrect_answers.append(f\"The {obj} is in the {incorrect_answer}\")\n",
    "\n",
    "\n",
    "    r = np.random.random()\n",
    "\n",
    "    if r < 0.75:\n",
    "        incorrect_answers.append(f\"In the {incorrect_answer}\")\n",
    "    elif r < 0.95:\n",
    "        possible_false_obj = list(possible_obj)\n",
    "        possible_false_obj.remove(obj)\n",
    "        false_obj = np.random.choice(possible_false_obj, size=1)[0]\n",
    "        incorrect_answers.append(f\"The {false_obj} is in the {correct_answer}\")\n",
    "    else:\n",
    "        incorrect_answers.append(\"\")\n",
    "\n",
    "    return correct_answers, incorrect_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_3_variations(question, correct_answer, possible_answers=[], possible_obj=[]):\n",
    "    correct_answers = [correct_answer]\n",
    "    obj = question.split(\"the \")[1].split(\" before\")[0]\n",
    "    correct_answers.append(f\"{obj} was in the {correct_answer}\")\n",
    "    correct_answers.append(f\"In the {correct_answer}\")\n",
    "\n",
    "    incorrect_answers = []\n",
    "    possible_incorrect_answers = list(possible_answers)\n",
    "    possible_incorrect_answers.remove(correct_answer)\n",
    "    incorrect_answer = np.random.choice(possible_incorrect_answers, size=1)[0]\n",
    "\n",
    "    incorrect_answers.append(incorrect_answer)\n",
    "    incorrect_answers.append(f\"The {obj} was in the {incorrect_answer}\")\n",
    "\n",
    "\n",
    "    r = np.random.random()\n",
    "\n",
    "    if r < 0.75:\n",
    "        incorrect_answers.append(f\"In the {incorrect_answer}\")\n",
    "    elif r < 0.95:\n",
    "        possible_false_obj = list(possible_obj)\n",
    "        possible_false_obj.remove(obj)\n",
    "        false_obj = np.random.choice(possible_false_obj, size=1)[0]\n",
    "        incorrect_answers.append(f\"The {false_obj} was in the {correct_answer}\")\n",
    "    else:\n",
    "        incorrect_answers.append(\"\")\n",
    "\n",
    "    return correct_answers, incorrect_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_task_4_variations(question, correct_answer, possible_answers=[]):\n",
    "    t4_directions = [\"north\", \"east\", \"south\", \"west\"]\n",
    "\n",
    "    correct_answers = [correct_answer]\n",
    "    correct_answers.append(f\"The {correct_answer}\")\n",
    "    direction = [d for d in t4_directions if d in question][0]\n",
    "    place = [p for p in possible_answers if p in question][0]\n",
    "    if \"of\" in question.split(\" \")[-1]:\n",
    "        correct_answers.append(\n",
    "            f\"The {place} is {direction} of {correct_answer}\"\n",
    "        )\n",
    "    else:\n",
    "        correct_answers.append(\n",
    "            f\"The {correct_answer} is {direction} of the {place}\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    incorrect_answers = []\n",
    "    possible_incorrect_answers = list(possible_answers)\n",
    "    possible_incorrect_answers.remove(correct_answer)\n",
    "    incorrect_answer = np.random.choice(possible_incorrect_answers, size=1)[0]\n",
    "\n",
    "    incorrect_answers.append(incorrect_answer)\n",
    "    \n",
    "    if \"of\" in question.split(\" \")[-1]:\n",
    "        incorrect_answers.append(\n",
    "            f\"The {correct_answer} is {direction} of the {place}\"\n",
    "        )\n",
    "    else:\n",
    "        incorrect_answers.append(\n",
    "            f\"The {place} is {direction} of {correct_answer}\"\n",
    "        )\n",
    "\n",
    "    r = np.random.random()\n",
    "\n",
    "    if r < 0.95:\n",
    "        incorrect_answers.append(f\"The {incorrect_answer}\")\n",
    "    else:\n",
    "        incorrect_answers.append(\"\")\n",
    "\n",
    "    return correct_answers, incorrect_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(passage, question, answer):\n",
    "    prompt = f\"Passage:\\n{passage}\\nQuestion:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_babi_df(data):\n",
    "    passages = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    prompts = []\n",
    "    labels = []\n",
    "    task_types = []\n",
    "\n",
    "    t1_questions = data[data[\"task\"] == 1][\"question\"].value_counts().index.to_list()\n",
    "    t1_names = [question.split(\" \")[2].split(\"?\")[0] for question in t1_questions]\n",
    "\n",
    "    t2_questions = data[data[\"task\"] == 2][\"question\"].value_counts().index.to_list()\n",
    "    t2_objects = list(set([question.split(\" \")[3].split(\"?\")[0] for question in t2_questions]))\n",
    "    t2_possible_answers = data[data[\"task\"] == 2][\"answer\"].value_counts().index.to_list()\n",
    "\n",
    "    t3_questions = data[data[\"task\"] == 3][\"question\"].value_counts().index.to_list()\n",
    "    t3_objects = list(set([question.split(\"the \")[1].split(\" before\")[0] for question in t3_questions]))\n",
    "    t3_possible_answers = data[data[\"task\"] == 3][\"answer\"].value_counts().index.to_list()\n",
    "\n",
    "    t4_possible_answers = data[data[\"task\"] == 4][\"answer\"].value_counts().index.to_list()\n",
    "\n",
    "    for task in range(1,5):\n",
    "        fn = {\n",
    "            1 : partial(generate_task_1_variations, possible_names=t1_names),\n",
    "            2 : partial(generate_task_2_variations, possible_answers=t2_possible_answers, possible_obj=t2_objects),\n",
    "            3 : partial(generate_task_3_variations, possible_answers=t3_possible_answers, possible_obj=t3_objects),\n",
    "            4 : partial(generate_task_4_variations, possible_answers=t4_possible_answers)\n",
    "        }[task]\n",
    "        for idx, row in data[data[\"task\"] == task].reset_index(drop=True).iterrows():\n",
    "            passages.extend([row[\"passage\"]] * 6)\n",
    "            questions.extend([row[\"question\"]] * 6)\n",
    "            correct_answers, incorrect_answers = fn(row[\"question\"], row[\"answer\"])\n",
    "            answers.extend(correct_answers)\n",
    "            answers.extend(incorrect_answers)\n",
    "            labels.extend([1] * 3)\n",
    "            labels.extend([0] * 3)\n",
    "            prompts.extend(\n",
    "                get_prompt(row[\"passage\"], row[\"question\"], answer)\n",
    "                for answer in correct_answers + incorrect_answers\n",
    "            )\n",
    "            task_types.extend([task] * 6)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"passage\": passages,\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"task_type\": task_types,\n",
    "        \"prompt\": prompts,\n",
    "        \"label\": labels\n",
    "    })\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = get_babi_df(babi_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"../data/processed/babi_data_small_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = get_babi_df(babi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val.to_csv(\"../data/processed/babi_data_small_val.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "int8_training = True  # https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/\n",
    "lora_training = True  # https://github.com/microsoft/LoRA\n",
    "autocast_training = True  # Trains with quantized weights. Only use if your hardware doesn't support int8_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec24d7fc0824405bb6d3e05f90deb99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8c591feb374f2ea50a8c6e677b3025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441627b8fea84ccba4c4c447c3e962d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de433a213650413b9e6533b0fc459b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/561 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7970aa017ca844e89449723743444a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cec83b4f7014278b8c201022cd0e603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at xhyi/PT_GPTNEO350_ATG and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xhyi/PT_GPTNEO350_ATG\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, \n",
    "            label2id=label2id, load_in_8bit=int8_training, low_cpu_mem_usage=int8_training)\n",
    "\n",
    "if not int8_training:\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 1024)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": \"<PAD>\"})\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"gpt-neo-350M\"\n",
    "project_name = \"bAbi-Judge\"\n",
    "store_locally = False  # Set False if you want to delete any config + checkpoint files in models/ (doesn't delete from subdirectories)\n",
    "\n",
    "batch_size = 16\n",
    "lr = 5e-5\n",
    "lr_scheduler = None  # \"cosine-annealing\" | None\n",
    "\n",
    "epochs = 5\n",
    "acc_every_batch = 250\n",
    "eval_every_batch = 250\n",
    "save_every_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used before creating dataloaders: 0.614098944\n",
      "Memory used after creating dataloaders: 0.614098944\n",
      "Memory used before optimization: 0.614098944\n",
      "Memory used after preparing for int8 training: 0.614098944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/share/virtualenvs/g5-rhys-y0VTy7Da/lib/python3.8/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used after lora: 0.614098944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfelixahofstaetter\u001b[0m (\u001b[33mdetecting-and-mitigating-deception\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/felix/g5-rhys/notebooks/wandb/run-20230815_094516-xhuad1pn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/detecting-and-mitigating-deception/bAbi-Judge/runs/xhuad1pn' target=\"_blank\">gpt-neo-350M</a></strong> to <a href='https://wandb.ai/detecting-and-mitigating-deception/bAbi-Judge' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/detecting-and-mitigating-deception/bAbi-Judge' target=\"_blank\">https://wandb.ai/detecting-and-mitigating-deception/bAbi-Judge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/detecting-and-mitigating-deception/bAbi-Judge/runs/xhuad1pn' target=\"_blank\">https://wandb.ai/detecting-and-mitigating-deception/bAbi-Judge/runs/xhuad1pn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/felix/.local/share/virtualenvs/g5-rhys-y0VTy7Da/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    }
   ],
   "source": [
    "train_judge_for_babi(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_name=model_name,\n",
    "    run_name=run_name,\n",
    "    project_name=project_name,\n",
    "    device=device,\n",
    "    lr=lr,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    autocast_training=autocast_training,\n",
    "    int8_training=int8_training,\n",
    "    lora_training=lora_training,\n",
    "    batch_size=batch_size,\n",
    "    store_locally=store_locally,\n",
    "    epochs=epochs,\n",
    "    acc_every_batch=acc_every_batch,\n",
    "    eval_every_batch=eval_every_batch,\n",
    "    save_every_epoch=save_every_epoch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5-rhys-OkinN51f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
